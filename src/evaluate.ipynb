{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## BERTScore , BARTScore , EM/F1 Score - Exact Match (%) , F1 Score (%)"
      ],
      "metadata": {
        "id": "c1ew76QoDvu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfBQ7Bz9CDjX",
        "outputId": "14a7ff77-02e0-4efa-c4bb-fff15e329235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "! pip install bert-score\n",
        "#! !pip install scipy transformers pandas torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 임의의 csv 2개 생성해서 테스트 해봄 (Please Modify this)"
      ],
      "metadata": {
        "id": "yp9l9_rajRpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 랜덤 텍스트 생성 함수\n",
        "def generate_random_text(num_samples):\n",
        "    random_texts = []\n",
        "    for _ in range(num_samples):\n",
        "        length = np.random.randint(5, 15)  # 문장의 길이는 5~15 단어 사이로 랜덤 설정\n",
        "        text = ' '.join(np.random.choice(['이것은', '랜덤', '텍스트', '생성', '예제입니다', '테스트', '데이터', '입니다', '여기에', '다양한', '단어가', '포함됩니다'], length))\n",
        "        random_texts.append(text)\n",
        "    return random_texts\n",
        "\n",
        "# 데이터 생성\n",
        "num_samples = 50\n",
        "reference_texts = generate_random_text(num_samples)\n",
        "predicted_texts = generate_random_text(num_samples)\n",
        "\n",
        "# 데이터프레임 생성\n",
        "reference_df = pd.DataFrame({'id': range(1, num_samples + 1), 'reference': reference_texts})\n",
        "predicted_df = pd.DataFrame({'id': range(1, num_samples + 1), 'predicted': predicted_texts})\n",
        "\n",
        "# CSV 파일로 저장\n",
        "reference_df.to_csv('reference.csv', index=False)\n",
        "predicted_df.to_csv('predicted.csv', index=False)\n",
        "\n",
        "print(\"CSV files have been created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cQ_b4WJecrF",
        "outputId": "c3508bbe-488c-472b-d7c1-9005d0e16356"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files have been created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "from scipy.special import softmax\n",
        "import torch\n",
        "\n",
        "\n",
        "# KoBERT 모델과 토크나이저 로드\n",
        "bert_model_name = \"monologg/kobert\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "bert_model = AutoModel.from_pretrained(bert_model_name).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# KoBART 모델과 토크나이저 로드\n",
        "bart_model_name = \"gogamza/kobart-base-v2\"\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# BARTScore 계산 함수 정의\n",
        "def bart_score(candidate, reference):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    # 토크나이징 및 입력 길이 제한\n",
        "    candidate_ids = bart_tokenizer(candidate, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "    reference_ids = bart_tokenizer(reference, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 입력된 텍스트의 logits 계산\n",
        "        candidate_logits = bart_model(candidate_ids).logits\n",
        "        reference_logits = bart_model(reference_ids).logits\n",
        "\n",
        "    # softmax를 사용하여 확률 계산\n",
        "    candidate_probs = softmax(candidate_logits.cpu().numpy(), axis=-1)\n",
        "    reference_probs = softmax(reference_logits.cpu().numpy(), axis=-1)\n",
        "\n",
        "    # BARTScore 계산 (로그 확률의 합)\n",
        "    bart_score_value = 0\n",
        "    for i in range(min(candidate_ids.shape[1], reference_ids.shape[1])):\n",
        "        bart_score_value += reference_probs[0, i, candidate_ids[0, i].item()]\n",
        "\n",
        "    return bart_score_value\n",
        "\n",
        "# 텍스트 정규화 함수 정의\n",
        "def normalize_answer(s):\n",
        "    \"\"\"소문자 변환, 불필요한 기호 제거 등을 통해 텍스트를 정규화\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "# F1 점수 계산 함수 정의\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = set(prediction_tokens) & set(ground_truth_tokens)\n",
        "    if len(common) == 0:\n",
        "        return 0\n",
        "    precision = len(common) / len(prediction_tokens)\n",
        "    recall = len(common) / len(ground_truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Exact Match 점수 계산 함수 정의\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return normalize_answer(prediction) == normalize_answer(ground_truth)\n",
        "\n",
        "# 전체 데이터셋에 대해 F1 및 Exact Match 점수를 계산하는 함수 정의\n",
        "def evaluate(predictions, references):\n",
        "    f1 = exact_match = total = 0\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        total += 1\n",
        "        exact_match += exact_match_score(pred, ref)\n",
        "        f1 += f1_score(pred, ref)\n",
        "    exact_match = 100.0 * exact_match / total\n",
        "    f1 = 100.0 * f1 / total\n",
        "    return {'exact_match': exact_match, 'f1': f1}\n",
        "\n",
        "\n",
        "# KoBERT를 사용하여 BERTScore 계산\n",
        "def bert_score_kobert(predictions, references):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    P, R, F1 = [], [], []\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        # 토크나이징\n",
        "        pred_tokens = bert_tokenizer(pred, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "        ref_tokens = bert_tokenizer(ref, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_embeddings = bert_model(**pred_tokens).last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "            ref_embeddings = bert_model(**ref_tokens).last_hidden_state.mean(dim=1).cpu().numpy()\n",
        "\n",
        "        # 코사인 유사도 계산\n",
        "        cosine_sim = cosine_similarity(pred_embeddings, ref_embeddings).item()\n",
        "        P.append(cosine_sim)\n",
        "        R.append(cosine_sim)\n",
        "        F1.append(cosine_sim)\n",
        "\n",
        "    return np.mean(P), np.mean(R), np.mean(F1)\n",
        "\n",
        "# CSV 파일로부터 데이터 불러오기\n",
        "reference_df = pd.read_csv(\"reference.csv\")\n",
        "predicted_df = pd.read_csv(\"predicted.csv\")\n",
        "\n",
        "# 정답과 예측값 리스트 생성\n",
        "references = reference_df['reference'].tolist()\n",
        "predictions = predicted_df['predicted'].tolist()\n",
        "\n",
        "# 평가 시간 측정 시작\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "# F1 및 Exact Match 점수 계산\n",
        "results = evaluate(predictions, references)\n",
        "print(\"Exact Match:\", results['exact_match'])\n",
        "print(\"F1 Score:\", results['f1'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O91Ea36enKm",
        "outputId": "bedd750a-9ec8-4795-9efa-7808ca7d65c5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
            "The class this function is called from is 'BartTokenizer'.\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match: 0.0\n",
            "F1 Score: 35.14734201436181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTScore 계산 (KoBERT 사용)\n",
        "P, R, F1 = bert_score_kobert(predictions, references)\n",
        "print(\"BERTScore (Precision):\", P)\n",
        "print(\"BERTScore (Recall):\", R)\n",
        "print(\"BERTScore (F1):\", F1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDb9dNKueufe",
        "outputId": "c56b7093-7f72-4225-98f0-9c969132ecf0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore (Precision): 0.9258360838890076\n",
            "BERTScore (Recall): 0.9258360838890076\n",
            "BERTScore (F1): 0.9258360838890076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BARTScore 계산\n",
        "bart_scores = [bart_score(pred, ref) for pred, ref in zip(predictions, references)]\n",
        "average_bart_score = np.mean(bart_scores)\n",
        "stddev_bart_score = np.std(bart_scores)\n",
        "\n",
        "# BARTScore 결과 출력\n",
        "print(f\"BARTScore (avg): {average_bart_score:.2f} ± {stddev_bart_score:.2f}\")\n",
        "\n",
        "# 평가 시간 측정 종료\n",
        "end_time = time.time()\n",
        "evaluation_time = end_time - start_time\n",
        "\n",
        "print(f\"Evaluation Time: {evaluation_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7yBUDxWgF9-",
        "outputId": "9bccf4ae-55a9-4f83-db40-b7dd89d4b1cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BARTScore (avg): 7.07 ± 3.74\n",
            "Evaluation Time: 87.68 seconds\n"
          ]
        }
      ]
    }
  ]
}
